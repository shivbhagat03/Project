# -*- coding: utf-8 -*-
"""Project1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oar1ZXfFLdepGHcgdtR_pdqKRMCHwLVV
"""

!pip install --ignore-installed blinker flask

!pip install sqlalchemy

!pip install requests beautifulsoup4 spacy nltk pandas sqlalchemy flask flask-restful
!python -m spacy download en_core_web_sm
!pip install vaderSentiment

import requests
from bs4 import BeautifulSoup

def fetch_article(url):
    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        article_text = " ".join([p.text for p in soup.find_all('p')])
        return article_text
    except Exception as e:
        print(f"Error fetching article: {e}")
        return None

url = "https://www.thehindu.com/news/international/hasina-involved-in-forced-disappearances-says-bangladesh-inquiry-commission/article68986255.ece"
article_text = fetch_article(url)
print(article_text)

import spacy

nlp = spacy.load("en_core_web_sm")

def extract_entities(text):
    if not text:
        return {"PERSON": [], "ORG": []}

    doc = nlp(text)
    entities = {"PERSON": [], "ORG": []}

    for ent in doc.ents:
        if ent.label_ == "PERSON":
            entities["PERSON"].append(ent.text)
        elif ent.label_ == "ORG":
            entities["ORG"].append(ent.text)


    entities["PERSON"] = list(set(entities["PERSON"]))
    entities["ORG"] = list(set(entities["ORG"]))
    return entities


entities = extract_entities(article_text)
print("Extracted Entities:", entities)

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyzer = SentimentIntensityAnalyzer()

def analyze_sentiment(text):
    if not text:
        return "Neutral"

    score = analyzer.polarity_scores(text)
    if score['compound'] > 0.05:
        return "Positive"
    elif score['compound'] < -0.05:
        return "Negative"
    else:
        return "Neutral"


sentiment = analyze_sentiment(article_text)
print("Sentiment:", sentiment)

from sqlalchemy import create_engine, Column, Integer, String, Text, JSON
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import IntegrityError


engine = create_engine('sqlite:///articles.db')
Base = declarative_base()

class Article(Base):
    __tablename__ = 'articles'
    id = Column(Integer, primary_key=True)
    url = Column(String, unique=True, nullable=False)
    text = Column(Text, nullable=False)
    entities = Column(JSON, nullable=False)
    sentiment = Column(String, nullable=False)

Base.metadata.create_all(engine)


Session = sessionmaker(bind=engine)
session = Session()

def save_to_database(url, text, entities, sentiment):
    try:
        article = Article(url=url, text=text, entities=entities, sentiment=sentiment)
        session.add(article)
        session.commit()
        print("Article saved successfully!")
    except IntegrityError:
        print(f"Article with URL '{url}' already exists in the database.")
        session.rollback()


save_to_database(url, article_text, entities, sentiment)

!pip install panel sqlalchemy requests beautifulsoup4 spacy vaderSentiment
!python -m spacy download en_core_web_sm

!pip install gradio

import gradio as gr
import requests
from bs4 import BeautifulSoup
import spacy
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from sqlalchemy import create_engine, Column, Integer, String, Text, JSON
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import IntegrityError


def fetch_article(url):
    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        article_text = " ".join([p.text for p in soup.find_all('p')])
        return article_text
    except Exception as e:
        return f"Error fetching article: {e}"


nlp = spacy.load("en_core_web_sm")

def extract_entities(text):
    if not text:
        return {"PERSON": [], "ORG": []}
    doc = nlp(text)
    entities = {"PERSON": [], "ORG": []}
    for ent in doc.ents:
        if ent.label_ == "PERSON":
            entities["PERSON"].append(ent.text)
        elif ent.label_ == "ORG":
            entities["ORG"].append(ent.text)

    entities["PERSON"] = list(set(entities["PERSON"]))
    entities["ORG"] = list(set(entities["ORG"]))
    return entities


analyzer = SentimentIntensityAnalyzer()

def analyze_sentiment(text):
    if not text:
        return "Neutral"
    score = analyzer.polarity_scores(text)
    if score['compound'] > 0.05:
        return "Positive"
    elif score['compound'] < -0.05:
        return "Negative"
    else:
        return "Neutral"


engine = create_engine('sqlite:///articles.db')
Base = declarative_base()

class Article(Base):
    __tablename__ = 'articles'
    id = Column(Integer, primary_key=True)
    url = Column(String, unique=True, nullable=False)
    text = Column(Text, nullable=False)
    entities = Column(JSON, nullable=False)
    sentiment = Column(String, nullable=False)

Base.metadata.create_all(engine)
Session = sessionmaker(bind=engine)
session = Session()


def save_to_database(url, text, entities, sentiment):
    try:
        article = Article(url=url, text=text, entities=entities, sentiment=sentiment)
        session.add(article)
        session.commit()
        return "Article saved successfully!"
    except IntegrityError:
        session.rollback()
        return f"Article with URL '{url}' already exists in the database."


def analyze_article(url):
    article_text = fetch_article(url)
    if article_text.startswith("Error"):
        return article_text, "", ""


    entities = extract_entities(article_text)
    sentiment = analyze_sentiment(article_text)


    save_result = save_to_database(url, article_text, entities, sentiment)


    return article_text, f"Sentiment: {sentiment}", f"Entities: {entities}"


interface = gr.Interface(
    fn=analyze_article,
    inputs=gr.Textbox(label="Enter Article URL"),
    outputs=[
        gr.Textbox(label="Article Text", lines=10, placeholder="Article text will appear here..."),
        gr.Textbox(label="Sentiment", placeholder="Sentiment will appear here..."),
        gr.Textbox(label="Entities", placeholder="Entities will appear here...")
    ],
    live=True
)


interface.launch()