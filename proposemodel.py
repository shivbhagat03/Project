# -*- coding: utf-8 -*-
"""Project2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14E1--3i7_7w4FlsdoBN5SZcnIH53Goii
"""

!pip install spacy datasets transformers
!python -m spacy download en_core_web_sm

import random
import spacy
from spacy.training.example import Example
import os


TRAIN_DATA = [
    ("Apple is a leading tech company.", {"entities": [(0, 5, "ORG")]}),
    ("Tim Cook is the CEO of Apple.", {"entities": [(0, 8, "PERSON"), (25, 30, "ORG")]}),
    ("Barack Obama was the 44th President of the United States.", {"entities": [(0, 12, "PERSON"), (39, 56, "ORG")]}),
]


checkpoint_dir = "/content/ner_model_checkpoints"

def create_training_examples(nlp, train_data):
    examples = []
    for text, annotations in train_data:
        doc = nlp.make_doc(text)
        example = Example.from_dict(doc, annotations)
        examples.append(example)
    return examples

def train_ner_model_with_checkpoints(train_data, output_dir, checkpoint_dir):
    nlp = spacy.blank("en")
    ner = nlp.add_pipe("ner", last=True)


    for _, annotations in train_data:
        for ent in annotations.get("entities"):
            ner.add_label(ent[2])


    optimizer = nlp.begin_training()


    examples = create_training_examples(nlp, train_data)


    for epoch in range(20):
        random.shuffle(examples)
        for batch in spacy.util.minibatch(examples, size=8):
            nlp.update(batch, sgd=optimizer)


        checkpoint_path = os.path.join(checkpoint_dir, f"checkpoint_epoch_{epoch}")
        if not os.path.exists(checkpoint_path):
            os.makedirs(checkpoint_path)
        nlp.to_disk(checkpoint_path)
        print(f"Checkpoint saved at epoch {epoch} to {checkpoint_path}")


    nlp.to_disk(output_dir)
    print(f"Model saved to {output_dir}")
    return nlp

nlp =train_ner_model_with_checkpoints(TRAIN_DATA, "/content/ner_model", checkpoint_dir)

nlp.to_disk("custom_ner_model")


custom_nlp = spacy.load("custom_ner_model")

import spacy

custom_nlp.to_disk('/content/custom_ner_model')

from google.colab import drive
drive.mount('/content/drive')

!cp -r /content/custom_ner_model /content/drive/MyDrive/